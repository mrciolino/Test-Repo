{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SISR - Single Image Super Resolution\n",
    "\n",
    "The goal of single image super resolution is to map a low resolution image to a high resolution image. We can then apply the mapping onto a poor quaility image to get a super resoluton image. The method used in this notebook is Super Resolution Generative Adverserial Network (SRGAN). SISR has not had heavy reserach in satilete imagery as compared to other types of imagery. To bring interest into SISR satilette imagery, we show an example here. We first load in the some test data, load in a pretrained model (trained on satilete imagery), and then test the model on some unseen data.  \n",
    "\n",
    "\n",
    "### SRGAN - Super Resolution Generative Adverserial Network\n",
    "\n",
    "The method we use is an GAN that uses a generator to apply super resolution to the low resolution images and a discrimitor that is trained to decipher between a real image and a fake image. This allows us to learn a real represention of a high resolution image. See the paper to read more about my exploration in SRGAN. This SRGAN tiles a starting image down into chips before running the super resolution. We then combine the super resolution tiles back into one image to remake the orginal image. \n",
    "\n",
    "Code is a heavily modified fork of https://github.com/deepak112/Keras-SRGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "\n",
    "sys.path.append(\"portfolio/utils\")\n",
    "os.chdir(\"../\")\n",
    "import Utils, Utils_model\n",
    "from Utils_model import VGG_LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters Config\n",
    "input_hig_res = \"portfolio/data\"\n",
    "ext = \"png\"\n",
    "number_of_images = 1\n",
    "downsample_ratio = 4 \n",
    "patch_size = (50,50,3)\n",
    "output_dir = \"portfolio/\"\n",
    "model = \"portfolio/models/gen_model_epoch3000_res50x50_ratio4.h5\"\n",
    "output_style = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: portfolio/data\n",
      "Found 1 images\n",
      "Image:   0  Shape: (320, 750, 3) -> Num Tiles: 8 Tile Shape: (2, 4) Padding: (80, 50)\n",
      "Converted images to (8, 200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "x_test_lr, x_test_hr, patch_info = Utils.load_data(input_hig_res, \n",
    "                                                   ext, \n",
    "                                                   number_of_images, \n",
    "                                                   0, # train test ratio\n",
    "                                                   downsample_ratio, \n",
    "                                                   patch_size, \n",
    "                                                   type = 'test_model_hr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "loss = VGG_LOSS(patch_size)\n",
    "model = load_model(model , custom_objects={'vgg_loss': loss.vgg_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model\n",
    "super_res_imgs = Utils.plot_generated_images_test_hr(output_dir, \n",
    "                                                     model, \n",
    "                                                     x_test_hr, \n",
    "                                                     x_test_lr, \n",
    "                                                     downsample_ratio, \n",
    "                                                     patch_info, \n",
    "                                                     output_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Super Res\n",
    "f, axarr = plt.subplots(1, 3, figsize=(25, 10))\n",
    "plt.suptitle('Super Resolution Images')\n",
    "axarr[0].imshow(super_res_imgs[1])\n",
    "axarr[1].imshow(super_res_imgs[2])\n",
    "axarr[2].imshow(super_res_imgs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Low Res\n",
    "f, axarr = plt.subplots(1, 3, figsize=(25, 10))\n",
    "plt.suptitle('Low Resolution Images')\n",
    "axarr[0].imshow(Utils.denormalize(x_test_lr[1]))\n",
    "axarr[1].imshow(Utils.denormalize(x_test_lr[2]))\n",
    "axarr[2].imshow(Utils.denormalize(x_test_lr[3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
